
Alumno@LAB704-04 MINGW64 ~
$ ssh appserver@192.168.13.250
appserver@192.168.13.250's password:
Permission denied, please try again.
appserver@192.168.13.250's password:
Permission denied, please try again.
appserver@192.168.13.250's password:
Welcome to Ubuntu 24.04.2 LTS (GNU/Linux 6.8.0-55-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/pro

 System information as of Fri Mar 21 02:15:55 PM UTC 2025

  System load:  0.58                Temperature:              63.0 C
  Usage of /:   69.9% of 912.36GB   Processes:                411
  Memory usage: 4%                  Users logged in:          0
  Swap usage:   0%                  IPv4 address for enp14s0: 192.168.13.250

 * Strictly confined Kubernetes makes edge and IoT secure. Learn how MicroK8s
   just raised the bar for easy, resilient and secure K8s cluster deployment.

   https://ubuntu.com/engage/secure-kubernetes-at-the-edge

Expanded Security Maintenance for Applications is not enabled.

19 updates can be applied immediately.
To see these additional updates run: apt list --upgradable

1 additional security update can be applied with ESM Apps.
Learn more about enabling ESM Apps service at https://ubuntu.com/esm


Last login: Thu Mar 20 15:27:14 2025 from 192.168.13.138
appserver@appserver:~$ cd research/
appserver@appserver:~/research$ ls
deepseek  deepseek_old
appserver@appserver:~/research$ ls -al
total 16
drwxrwxr-x  4 appserver appserver 4096 Mar 21 14:11 .
drwxr-x--- 39 appserver appserver 4096 Mar 19 21:59 ..
drwxrwxr-x  5 appserver appserver 4096 Mar 21 14:14 deepseek
drwxrwxr-x  4 appserver appserver 4096 Mar 20 15:36 deepseek_old
appserver@appserver:~/research$ cd deepseek
appserver@appserver:~/research/deepseek$ ls
form_1  form_2  README.md
appserver@appserver:~/research/deepseek$ cd form_1
appserver@appserver:~/research/deepseek/form_1$ ls
01_test_setup.py               03_finetune_deepseek.py  custom_dataset.json
02_create_dataset.py           04_convert_to_ollama.py  env
03_finetune_deepseek_macos.py  05_Modelfile_custom      README.md
appserver@appserver:~/research/deepseek/form_1$ cat README.md
# Form 1

## Prepare environment
python3 -m venv env
source env/bin/activate

## Install
pip install torch torchvision torchaudio
pip install transformers datasets accelerate peft bitsandbytes wandb
pip install numpy pandas scikit-learn matplotlib jupyterlab

## Step

### 1.- Create data set
python 02_create_dataset.py

### 2.- Run the Fine-tuning
python 03_finetune_deepseek.py

### 3.- Run the Fine-tuning
python 03_finetune_deepseek.py

### 4.- Export to Ollama Format
mkdir -p ollama_model
python 04_convert_to_ollama.py
ollama create custom-deepseek -f 05_Modelfile_custom

### 5.- Test Model
ollama run custom-deepseekappserver@appserver:~/
appserver@appserver:~/research/deepseek/form_1$ source env/bin/activate
(env) appserver@appserver:~/research/deepseek/form_1$ pip install torch torchvision torchaudio
Collecting torch
  Using cached torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)
Collecting torchvision
  Using cached torchvision-0.21.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)
Collecting torchaudio
  Using cached torchaudio-2.6.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)
Collecting filelock (from torch)
  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)
Collecting typing-extensions>=4.10.0 (from torch)
  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)
Collecting networkx (from torch)
  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
Collecting jinja2 (from torch)
  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec (from torch)
  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)
Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)
  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)
  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)
  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)
  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)
  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)
  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-curand-cu12==10.3.5.147 (from torch)
  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)
  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)
  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)
  Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)
Collecting nvidia-nccl-cu12==2.21.5 (from torch)
  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-nvtx-cu12==12.4.127 (from torch)
  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)
  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting triton==3.2.0 (from torch)
  Using cached triton-3.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)
Collecting setuptools (from torch)
  Downloading setuptools-77.0.3-py3-none-any.whl.metadata (6.6 kB)
Collecting sympy==1.13.1 (from torch)
  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)
  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Collecting numpy (from torchvision)
  Using cached numpy-2.2.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)
Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)
  Using cached pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch)
  Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)
Using cached torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl (766.6 MB)
Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)
Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)
Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)
Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)
Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)
Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)
Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)
Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)
Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)
Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)
Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)
Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)
Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)
Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)
Using cached triton-3.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)
Using cached torchvision-0.21.0-cp312-cp312-manylinux1_x86_64.whl (7.2 MB)
Using cached torchaudio-2.6.0-cp312-cp312-manylinux1_x86_64.whl (3.4 MB)
Using cached pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)
Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Using cached filelock-3.18.0-py3-none-any.whl (16 kB)
Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)
Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)
Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
Using cached numpy-2.2.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)
Downloading setuptools-77.0.3-py3-none-any.whl (1.3 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 9.4 MB/s eta 0:00:00
Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)
Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)
Installing collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, setuptools, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio

Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.3.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pillow-11.1.0 setuptools-77.0.3 sympy-1.13.1 torch-2.6.0 torchaudio-2.6.0 torchvision-0.21.0 triton-3.2.0 typing-extensions-4.12.2
(env) appserver@appserver:~/research/deepseek/form_1$
(env) appserver@appserver:~/research/deepseek/form_1$ cat README.md
# Form 1

## Prepare environment
python3 -m venv env
source env/bin/activate

## Install
pip install torch torchvision torchaudio
pip install transformers datasets accelerate peft bitsandbytes wandb
pip install numpy pandas scikit-learn matplotlib jupyterlab

## Step

### 1.- Create data set
python 02_create_dataset.py

### 2.- Run the Fine-tuning
python 03_finetune_deepseek.py

### 3.- Run the Fine-tuning
python 03_finetune_deepseek.py

### 4.- Export to Ollama Format
mkdir -p ollama_model
python 04_convert_to_ollama.py
ollama create custom-deepseek -f 05_Modelfile_custom

### 5.- Test Model
(env) appserver@appserver:~/research/deepseek/form_1$ pip install transformers datasets accelerate peft bitsandbytes wandbte peft bitsandbytes wandb
Collecting transformers
  Downloading transformers-4.50.0-py3-none-any.whl.metadata (39 kB)
Collecting datasets
  Using cached datasets-3.4.1-py3-none-any.whl.metadata (19 kB)
Collecting accelerate
  Using cached accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)
Collecting peft
  Using cached peft-0.15.0-py3-none-any.whl.metadata (13 kB)
Collecting bitsandbytes
  Using cached bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)
Collecting wandb
  Using cached wandb-0.19.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)
Requirement already satisfied: filelock in ./env/lib/python3.12/site-packages (from transformers) (3.18.0)
Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)
  Using cached huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)
Requirement already satisfied: numpy>=1.17 in ./env/lib/python3.12/site-packages (from transformers) (2.2.4)
Collecting packaging>=20.0 (from transformers)
  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)
Collecting pyyaml>=5.1 (from transformers)
  Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)
Collecting regex!=2019.12.17 (from transformers)
  Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)
Collecting requests (from transformers)
  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)
Collecting tokenizers<0.22,>=0.21 (from transformers)
  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)
Collecting safetensors>=0.4.3 (from transformers)
  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)
Collecting tqdm>=4.27 (from transformers)
  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
Collecting pyarrow>=15.0.0 (from datasets)
  Using cached pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)
Collecting dill<0.3.9,>=0.3.0 (from datasets)
  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)
Collecting pandas (from datasets)
  Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)
Collecting xxhash (from datasets)
  Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)
Collecting multiprocess<0.70.17 (from datasets)
  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)
Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)
  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)
Collecting aiohttp (from datasets)
  Using cached aiohttp-3.11.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)
Collecting psutil (from accelerate)
  Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)
Requirement already satisfied: torch>=2.0.0 in ./env/lib/python3.12/site-packages (from accelerate) (2.6.0)
Collecting click!=8.0.0,>=7.1 (from wandb)
  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)
Collecting docker-pycreds>=0.4.0 (from wandb)
  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)
Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)
  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)
Collecting platformdirs (from wandb)
  Using cached platformdirs-4.3.7-py3-none-any.whl.metadata (11 kB)
Collecting protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 (from wandb)
  Using cached protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)
Collecting pydantic<3,>=2.6 (from wandb)
  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)
Collecting sentry-sdk>=2.0.0 (from wandb)
  Downloading sentry_sdk-2.24.0-py2.py3-none-any.whl.metadata (10 kB)
Collecting setproctitle (from wandb)
  Using cached setproctitle-1.3.5-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)
Requirement already satisfied: setuptools in ./env/lib/python3.12/site-packages (from wandb) (77.0.3)
Collecting six>=1.4.0 (from docker-pycreds>=0.4.0->wandb)
  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)
  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)
Collecting aiosignal>=1.1.2 (from aiohttp->datasets)
  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)
Collecting attrs>=17.3.0 (from aiohttp->datasets)
  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)
Collecting frozenlist>=1.1.1 (from aiohttp->datasets)
  Using cached frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)
Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)
  Using cached multidict-6.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)
Collecting propcache>=0.2.0 (from aiohttp->datasets)
  Using cached propcache-0.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)
Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)
  Using cached yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)
Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: typing-extensions>=3.7.4.3 in ./env/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)
Collecting annotated-types>=0.6.0 (from pydantic<3,>=2.6->wandb)
  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)
Collecting pydantic-core==2.27.2 (from pydantic<3,>=2.6->wandb)
  Using cached pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)
Collecting charset-normalizer<4,>=2 (from requests->transformers)
  Using cached charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)
Collecting idna<4,>=2.5 (from requests->transformers)
  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)
Collecting urllib3<3,>=1.21.1 (from requests->transformers)
  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)
Collecting certifi>=2017.4.17 (from requests->transformers)
  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)
Requirement already satisfied: networkx in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.2)
Requirement already satisfied: jinja2 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)
Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)
Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)
Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)
Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)
Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)
Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)
Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.6.2)
Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.21.5)
Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)
Requirement already satisfied: triton==3.2.0 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.2.0)
Requirement already satisfied: sympy==1.13.1 in ./env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./env/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)
Collecting python-dateutil>=2.8.2 (from pandas->datasets)
  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
Collecting pytz>=2020.1 (from pandas->datasets)
  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)
Collecting tzdata>=2022.7 (from pandas->datasets)
  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)
Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)
  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)
Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)
Downloading transformers-4.50.0-py3-none-any.whl (10.2 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.2/10.2 MB 11.4 MB/s eta 0:00:00
Using cached datasets-3.4.1-py3-none-any.whl (487 kB)
Using cached accelerate-1.5.2-py3-none-any.whl (345 kB)
Using cached peft-0.15.0-py3-none-any.whl (410 kB)
Using cached bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)
Using cached wandb-0.19.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.8 MB)
Using cached click-8.1.8-py3-none-any.whl (98 kB)
Using cached dill-0.3.8-py3-none-any.whl (116 kB)
Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)
Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)
Using cached aiohttp-3.11.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)
Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)
Using cached huggingface_hub-0.29.3-py3-none-any.whl (468 kB)
Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)
Using cached packaging-24.2-py3-none-any.whl (65 kB)
Using cached protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)
Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)
Using cached pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (42.1 MB)
Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)
Using cached pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)
Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)
Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)
Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)
Downloading sentry_sdk-2.24.0-py2.py3-none-any.whl (336 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 336.9/336.9 kB 9.5 MB/s eta 0:00:00
Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)
Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)
Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)
Using cached platformdirs-4.3.7-py3-none-any.whl (18 kB)
Using cached setproctitle-1.3.5-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)
Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)
Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)
Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)
Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)
Using cached attrs-25.3.0-py3-none-any.whl (63 kB)
Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)
Using cached charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (145 kB)
Using cached frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)
Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)
Using cached idna-3.10-py3-none-any.whl (70 kB)
Using cached multidict-6.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)
Using cached propcache-0.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)
Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)
Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)
Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)
Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)
Using cached yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)
Using cached smmap-5.0.2-py3-none-any.whl (24 kB)
Installing collected packages: pytz, xxhash, urllib3, tzdata, tqdm, smmap, six, setproctitle, safetensors, regex, pyyaml, pydantic-core, pyarrow, psutil, protobuf, propcache, platformdirs, packaging, multidict, idna, fsspec, frozenlist, dill, click, charset-normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, sentry-sdk, requests, python-dateutil, pydantic, multiprocess, gitdb, docker-pycreds, aiosignal, pandas, huggingface-hub, gitpython, aiohttp, wandb, tokenizers, bitsandbytes, accelerate, transformers, datasets, peft
  Attempting uninstall: fsspec
    Found existing installation: fsspec 2025.3.0
    Uninstalling fsspec-2025.3.0:
      Successfully uninstalled fsspec-2025.3.0
Successfully installed accelerate-1.5.2 aiohappyeyeballs-2.6.1 aiohttp-3.11.14 aiosignal-1.3.2 annotated-types-0.7.0 attrs-25.3.0 bitsandbytes-0.45.3 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 datasets-3.4.1 dill-0.3.8 docker-pycreds-0.4.0 frozenlist-1.5.0 fsspec-2024.12.0 gitdb-4.0.12 gitpython-3.1.44 huggingface-hub-0.29.3 idna-3.10 multidict-6.2.0 multiprocess-0.70.16 packaging-24.2 pandas-2.2.3 peft-0.15.0 platformdirs-4.3.7 propcache-0.3.0 protobuf-5.29.4 psutil-7.0.0 pyarrow-19.0.1 pydantic-2.10.6 pydantic-core-2.27.2 python-dateutil-2.9.0.post0 pytz-2025.1 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 sentry-sdk-2.24.0 setproctitle-1.3.5 six-1.17.0 smmap-5.0.2 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.50.0 tzdata-2025.1 urllib3-2.3.0 wandb-0.19.8 xxhash-3.5.0 yarl-1.18.3
(env) appserver@appserver:~/research/deepseek/form_1$ cat README.md
# Form 1

## Prepare environment
python3 -m venv env
source env/bin/activate

## Install
pip install torch torchvision torchaudio
pip install transformers datasets accelerate peft bitsandbytes wandb
pip install numpy pandas scikit-learn matplotlib jupyterlab

## Step

### 1.- Create data set
python 02_create_dataset.py

### 2.- Run the Fine-tuning
python 03_finetune_deepseek.py

### 3.- Run the Fine-tuning
python 03_finetune_deepseek.py

### 4.- Export to Ollama Format
mkdir -p ollama_model
python 04_convert_to_ollama.py
ollama create custom-deepseek -f 05_Modelfile_custom

### 5.- Test Model
ollama run custom-deepseek(env) appserver@appserver:~/pip install numpy pandas scikit-learn matplotlib jupyterlabearn matplotlib jupyterlab
Requirement already satisfied: numpy in ./env/lib/python3.12/site-packages (2.2.4)
Requirement already satisfied: pandas in ./env/lib/python3.12/site-packages (2.2.3)
Collecting scikit-learn
  Using cached scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)
Collecting matplotlib
  Using cached matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)
Collecting jupyterlab
  Using cached jupyterlab-4.3.6-py3-none-any.whl.metadata (16 kB)
Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.12/site-packages (from pandas) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.12/site-packages (from pandas) (2025.1)
Requirement already satisfied: tzdata>=2022.7 in ./env/lib/python3.12/site-packages (from pandas) (2025.1)
Collecting scipy>=1.6.0 (from scikit-learn)
  Using cached scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)
Collecting joblib>=1.2.0 (from scikit-learn)
  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)
Collecting threadpoolctl>=3.1.0 (from scikit-learn)
  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)
Collecting contourpy>=1.0.1 (from matplotlib)
  Using cached contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)
Collecting cycler>=0.10 (from matplotlib)
  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)
Collecting fonttools>=4.22.0 (from matplotlib)
  Using cached fonttools-4.56.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)
Collecting kiwisolver>=1.3.1 (from matplotlib)
  Using cached kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)
Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.12/site-packages (from matplotlib) (24.2)
Requirement already satisfied: pillow>=8 in ./env/lib/python3.12/site-packages (from matplotlib) (11.1.0)
Collecting pyparsing>=2.3.1 (from matplotlib)
  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)
Collecting async-lru>=1.0.0 (from jupyterlab)
  Using cached async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)
Collecting httpx>=0.25.0 (from jupyterlab)
  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)
Collecting ipykernel>=6.5.0 (from jupyterlab)
  Using cached ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)
Requirement already satisfied: jinja2>=3.0.3 in ./env/lib/python3.12/site-packages (from jupyterlab) (3.1.6)
Collecting jupyter-core (from jupyterlab)
  Using cached jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)
Collecting jupyter-lsp>=2.0.0 (from jupyterlab)
  Using cached jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)
Collecting jupyter-server<3,>=2.4.0 (from jupyterlab)
  Using cached jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)
Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab)
  Using cached jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)
Collecting notebook-shim>=0.2 (from jupyterlab)
  Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)
Requirement already satisfied: setuptools>=40.8.0 in ./env/lib/python3.12/site-packages (from jupyterlab) (77.0.3)
Collecting tornado>=6.2.0 (from jupyterlab)
  Using cached tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)
Collecting traitlets (from jupyterlab)
  Using cached traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)
Collecting anyio (from httpx>=0.25.0->jupyterlab)
  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)
Requirement already satisfied: certifi in ./env/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab) (2025.1.31)
Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab)
  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)
Requirement already satisfied: idna in ./env/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab) (3.10)
Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.25.0->jupyterlab)
  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)
Collecting comm>=0.1.1 (from ipykernel>=6.5.0->jupyterlab)
  Using cached comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)
Collecting debugpy>=1.6.5 (from ipykernel>=6.5.0->jupyterlab)
  Using cached debugpy-1.8.13-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)
Collecting ipython>=7.23.1 (from ipykernel>=6.5.0->jupyterlab)
  Using cached ipython-9.0.2-py3-none-any.whl.metadata (4.3 kB)
Collecting jupyter-client>=6.1.12 (from ipykernel>=6.5.0->jupyterlab)
  Using cached jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)
Collecting matplotlib-inline>=0.1 (from ipykernel>=6.5.0->jupyterlab)
  Using cached matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)
Collecting nest-asyncio (from ipykernel>=6.5.0->jupyterlab)
  Using cached nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)
Requirement already satisfied: psutil in ./env/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (7.0.0)
Collecting pyzmq>=24 (from ipykernel>=6.5.0->jupyterlab)
  Using cached pyzmq-26.3.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.2 kB)
Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.12/site-packages (from jinja2>=3.0.3->jupyterlab) (3.0.2)
Requirement already satisfied: platformdirs>=2.5 in ./env/lib/python3.12/site-packages (from jupyter-core->jupyterlab) (4.3.7)
Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)
Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)
Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)
Collecting nbconvert>=6.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)
Collecting nbformat>=5.3.0 (from jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)
Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)
Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)
Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)
Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)
Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)
Collecting babel>=2.10 (from jupyterlab-server<3,>=2.27.1->jupyterlab)
  Using cached babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)
Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab)
  Using cached json5-0.10.0-py3-none-any.whl.metadata (34 kB)
Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab)
  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)
Requirement already satisfied: requests>=2.31 in ./env/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.32.3)
Requirement already satisfied: six>=1.5 in ./env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)
Collecting sniffio>=1.1 (from anyio->httpx>=0.25.0->jupyterlab)
  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)
Requirement already satisfied: typing_extensions>=4.5 in ./env/lib/python3.12/site-packages (from anyio->httpx>=0.25.0->jupyterlab) (4.12.2)
Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)
Collecting decorator (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab)
  Using cached decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)
Collecting ipython-pygments-lexers (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab)
  Using cached ipython_pygments_lexers-1.1.1-py3-none-any.whl.metadata (1.1 kB)
Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab)
  Using cached jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)
Collecting pexpect>4.3 (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab)
  Using cached pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)
Collecting prompt_toolkit<3.1.0,>=3.0.41 (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab)
  Using cached prompt_toolkit-3.0.50-py3-none-any.whl.metadata (6.6 kB)
Collecting pygments>=2.4.0 (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab)
  Using cached pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)
Collecting stack_data (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab)
  Using cached stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)
Requirement already satisfied: attrs>=22.2.0 in ./env/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (25.3.0)
Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab)
  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)
Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab)
  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)
Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab)
  Using cached rpds_py-0.23.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)
Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)
Requirement already satisfied: pyyaml>=5.3 in ./env/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.2)
Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)
Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting beautifulsoup4 (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)
Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached bleach-6.2.0-py3-none-any.whl.metadata (30 kB)
Collecting defusedxml (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)
Collecting jupyterlab-pygments (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)
Collecting mistune<4,>=2.0.3 (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached mistune-3.1.3-py3-none-any.whl.metadata (1.8 kB)
Collecting nbclient>=0.5.0 (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)
Collecting pandocfilters>=1.4.1 (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)
Collecting fastjsonschema>=2.15 (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)
Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (3.4.1)
Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.3.0)
Collecting ptyprocess (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)
Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)
Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)
Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab)
  Using cached parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)
Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)
Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)
Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)
Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)
Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)
Collecting wcwidth (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab)
  Using cached wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)
Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)
Collecting executing>=1.2.0 (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab)
  Using cached executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)
Collecting asttokens>=2.1.0 (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab)
  Using cached asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)
Collecting pure-eval (from stack_data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab)
  Using cached pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)
Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)
Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)
Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab)
  Using cached types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)
Using cached scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)
Using cached matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)
Using cached jupyterlab-4.3.6-py3-none-any.whl (11.7 MB)
Using cached async_lru-2.0.5-py3-none-any.whl (6.1 kB)
Using cached contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)
Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)
Using cached fonttools-4.56.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)
Using cached httpx-0.28.1-py3-none-any.whl (73 kB)
Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)
Using cached ipykernel-6.29.5-py3-none-any.whl (117 kB)
Using cached joblib-1.4.2-py3-none-any.whl (301 kB)
Using cached jupyter_core-5.7.2-py3-none-any.whl (28 kB)
Using cached jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)
Using cached jupyter_server-2.15.0-py3-none-any.whl (385 kB)
Using cached jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)
Using cached kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)
Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)
Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)
Using cached scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)
Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)
Using cached tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (437 kB)
Using cached traitlets-5.14.3-py3-none-any.whl (85 kB)
Using cached anyio-4.9.0-py3-none-any.whl (100 kB)
Using cached argon2_cffi-23.1.0-py3-none-any.whl (15 kB)
Using cached babel-2.17.0-py3-none-any.whl (10.2 MB)
Using cached comm-0.2.2-py3-none-any.whl (7.2 kB)
Using cached debugpy-1.8.13-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)
Using cached ipython-9.0.2-py3-none-any.whl (600 kB)
Using cached json5-0.10.0-py3-none-any.whl (34 kB)
Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)
Using cached jupyter_client-8.6.3-py3-none-any.whl (106 kB)
Using cached jupyter_events-0.12.0-py3-none-any.whl (19 kB)
Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)
Using cached matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)
Using cached nbconvert-7.16.6-py3-none-any.whl (258 kB)
Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)
Using cached overrides-7.7.0-py3-none-any.whl (17 kB)
Using cached prometheus_client-0.21.1-py3-none-any.whl (54 kB)
Using cached pyzmq-26.3.0-cp312-cp312-manylinux_2_28_x86_64.whl (859 kB)
Using cached Send2Trash-1.8.3-py3-none-any.whl (18 kB)
Using cached terminado-0.18.1-py3-none-any.whl (14 kB)
Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)
Using cached nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)
Using cached bleach-6.2.0-py3-none-any.whl (163 kB)
Using cached fastjsonschema-2.21.1-py3-none-any.whl (23 kB)
Using cached h11-0.14.0-py3-none-any.whl (58 kB)
Using cached jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)
Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)
Using cached mistune-3.1.3-py3-none-any.whl (53 kB)
Using cached nbclient-0.10.2-py3-none-any.whl (25 kB)
Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)
Using cached pexpect-4.9.0-py2.py3-none-any.whl (63 kB)
Using cached prompt_toolkit-3.0.50-py3-none-any.whl (387 kB)
Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)
Using cached pygments-2.19.1-py3-none-any.whl (1.2 MB)
Using cached python_json_logger-3.3.0-py3-none-any.whl (15 kB)
Using cached referencing-0.36.2-py3-none-any.whl (26 kB)
Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)
Using cached rpds_py-0.23.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (391 kB)
Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)
Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)
Using cached beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)
Using cached decorator-5.2.1-py3-none-any.whl (9.2 kB)
Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)
Using cached ipython_pygments_lexers-1.1.1-py3-none-any.whl (8.1 kB)
Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)
Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)
Using cached stack_data-0.6.3-py3-none-any.whl (24 kB)
Using cached asttokens-3.0.0-py3-none-any.whl (26 kB)
Using cached cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479 kB)
Using cached executing-2.2.0-py2.py3-none-any.whl (26 kB)
Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)
Using cached parso-0.8.4-py2.py3-none-any.whl (103 kB)
Using cached soupsieve-2.6-py3-none-any.whl (36 kB)
Using cached tinycss2-1.4.0-py3-none-any.whl (26 kB)
Using cached webcolors-24.11.1-py3-none-any.whl (14 kB)
Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)
Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)
Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)
Using cached pure_eval-0.2.3-py3-none-any.whl (11 kB)
Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)
Using cached wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)
Using cached arrow-1.3.0-py3-none-any.whl (66 kB)
Using cached pycparser-2.22-py3-none-any.whl (117 kB)
Using cached types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)
Installing collected packages: webencodings, wcwidth, pure-eval, ptyprocess, fastjsonschema, websocket-client, webcolors, uri-template, types-python-dateutil, traitlets, tornado, tinycss2, threadpoolctl, soupsieve, sniffio, send2trash, scipy, rpds-py, rfc3986-validator, rfc3339-validator, pyzmq, python-json-logger, pyparsing, pygments, pycparser, prompt_toolkit, prometheus-client, pexpect, parso, pandocfilters, overrides, nest-asyncio, mistune, kiwisolver, jupyterlab-pygments, jsonpointer, json5, joblib, h11, fqdn, fonttools, executing, defusedxml, decorator, debugpy, cycler, contourpy, bleach, babel, async-lru, asttokens, terminado, stack_data, scikit-learn, referencing, matplotlib-inline, matplotlib, jupyter-core, jedi, ipython-pygments-lexers, httpcore, comm, cffi, beautifulsoup4, arrow, anyio, jupyter-server-terminals, jupyter-client, jsonschema-specifications, isoduration, ipython, httpx, argon2-cffi-bindings, jsonschema, ipykernel, argon2-cffi, nbformat, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab
Successfully installed anyio-4.9.0 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 asttokens-3.0.0 async-lru-2.0.5 babel-2.17.0 beautifulsoup4-4.13.3 bleach-6.2.0 cffi-1.17.1 comm-0.2.2 contourpy-1.3.1 cycler-0.12.1 debugpy-1.8.13 decorator-5.2.1 defusedxml-0.7.1 executing-2.2.0 fastjsonschema-2.21.1 fonttools-4.56.0 fqdn-1.5.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 ipykernel-6.29.5 ipython-9.0.2 ipython-pygments-lexers-1.1.1 isoduration-20.11.0 jedi-0.19.2 joblib-1.4.2 json5-0.10.0 jsonpointer-3.0.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 jupyter-client-8.6.3 jupyter-core-5.7.2 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.3.6 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.3 kiwisolver-1.4.8 matplotlib-3.10.1 matplotlib-inline-0.1.7 mistune-3.1.3 nbclient-0.10.2 nbconvert-7.16.6 nbformat-5.10.4 nest-asyncio-1.6.0 notebook-shim-0.2.4 overrides-7.7.0 pandocfilters-1.5.1 parso-0.8.4 pexpect-4.9.0 prometheus-client-0.21.1 prompt_toolkit-3.0.50 ptyprocess-0.7.0 pure-eval-0.2.3 pycparser-2.22 pygments-2.19.1 pyparsing-3.2.1 python-json-logger-3.3.0 pyzmq-26.3.0 referencing-0.36.2 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.23.1 scikit-learn-1.6.1 scipy-1.15.2 send2trash-1.8.3 sniffio-1.3.1 soupsieve-2.6 stack_data-0.6.3 terminado-0.18.1 threadpoolctl-3.6.0 tinycss2-1.4.0 tornado-6.4.2 traitlets-5.14.3 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0 wcwidth-0.2.13 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.8.0
(env) appserver@appserver:~/research/deepseek/form_1$ cat README.md
# Form 1

## Prepare environment
python3 -m venv env
source env/bin/activate

## Install
pip install torch torchvision torchaudio
pip install transformers datasets accelerate peft bitsandbytes wandb
pip install numpy pandas scikit-learn matplotlib jupyterlab

## Step

### 1.- Create data set
python 02_create_dataset.py

### 2.- Run the Fine-tuning
python 03_finetune_deepseek.py

### 3.- Run the Fine-tuning
python 03_finetune_deepseek.py

### 4.- Export to Ollama Format
mkdir -p ollama_model
python 04_convert_to_ollama.py
ollama create custom-deepseek -f 05_Modelfile_custom

### 5.- Test Model
ollama run custom-deepseek(env) appserver@appserver:~/research/deepseek/form_1$ python 02_create_dataset.python 02_create_dataset.py
Dataset created successfully with 5 examples.
(env) appserver@appserver:~/research/deepseek/form_1$ python 03_finetune_deepseek.py
Using CPU (MPS not available)
Loading model deepseek-ai/deepseek-llm-7b-base...
Loading checkpoint shards: 100%|███████████████████████████████████████████| 2/2 [00:11<00:00,  5.76s/it]
Applying LoRA adapters to model...
Loading and preprocessing dataset...
Map: 100%|████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 1406.26 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Starting training...
  0%|                                                                             | 0/10 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
/home/appserver/research/deepseek/form_1/env/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
{'loss': 1.8571, 'grad_norm': 0.18915151059627533, 'learning_rate': 0.0001, 'epoch': 5.0}
{'loss': 1.8087, 'grad_norm': 0.3323996663093567, 'learning_rate': 0.0, 'epoch': 10.0}
{'train_runtime': 40.6963, 'train_samples_per_second': 1.229, 'train_steps_per_second': 0.246, 'train_loss': 1.8328927040100098, 'epoch': 10.0}
100%|████████████████████████████████████████████████████████████████████| 10/10 [00:40<00:00,  4.07s/it]
Saving model...
Fine-tuning complete!
(env) appserver@appserver:~/research/deepseek/form_1$ cat README.md
# Form 1

## Prepare environment
python3 -m venv env
source env/bin/activate

## Install
pip install torch torchvision torchaudio
pip install transformers datasets accelerate peft bitsandbytes wandb
pip install numpy pandas scikit-learn matplotlib jupyterlab

## Step

### 1.- Create data set
python 02_create_dataset.py

### 2.- Run the Fine-tuning
python 03_finetune_deepseek.py

### 3.- Run the Fine-tuning
python 03_finetune_deepseek.py

### 4.- Export to Ollama Format
mkdir -p ollama_model
python 04_convert_to_ollama.py
ollama create custom-deepseek -f 05_Modelfile_custom

### 5.- Test Model
ollama run custom-deepseek(env) appserver@appserver:~/research/deepseek/form_1$ cd ..
(env) appserver@appserver:~/research/deepseek$ git pull
remote: Enumerating objects: 7, done.
remote: Counting objects: 100% (7/7), done.
remote: Compressing objects: 100% (1/1), done.
remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)
Unpacking objects: 100% (4/4), 401 bytes | 401.00 KiB/s, done.
From https://github.com/jgomezz/deepseek
   9305a45..56c436a  main       -> origin/main
Updating 9305a45..56c436a
Fast-forward
 form_1/README.md | 8 ++++----
 1 file changed, 4 insertions(+), 4 deletions(-)
(env) appserver@appserver:~/research/deepseek$ cd form_1/
(env) appserver@appserver:~/research/deepseek/form_1$ ls
01_test_setup.py               03_finetune_deepseek.py  custom_dataset.json    env
02_create_dataset.py           04_convert_to_ollama.py  deepseek-custom        README.md
03_finetune_deepseek_macos.py  05_Modelfile_custom      deepseek-custom-final
(env) appserver@appserver:~/research/deepseek/form_1$ cat README.md
# Form 1

## Prepare environment
python3 -m venv env
source env/bin/activate

## Install
pip install torch torchvision torchaudio
pip install transformers datasets accelerate peft bitsandbytes wandb
pip install numpy pandas scikit-learn matplotlib jupyterlab

## Step

### 1.- Enviroment test (optional)
python 01_test_setup.py

### 2.- Create data set
python 02_create_dataset.py

### 3.- Run the Fine-tuning
python 03_finetune_deepseek.py

### 4.- Export to Ollama Format
mkdir -p ollama_model
python 04_convert_to_ollama.py
ollama create custom-deepseek -f 05_Modelfile_custom

### 5.- Test Model
ollama run custom-deepseek(env) appserver@appserver:~/research/deepseek/form_1$ mkdir -p ollama_model
(env) appserver@appserver:~/research/deepseek/form_1$ python 04_convert_to_ollama.py
Loading checkpoint shards: 100%|███████████████████████████████████████████| 2/2 [00:01<00:00,  1.08it/s]
Some parameters are on the meta device because they were offloaded to the cpu.
/home/appserver/research/deepseek/form_1/env/lib/python3.12/site-packages/transformers/modeling_utils.py:3405: UserWarning: Attempting to save a model with offloaded modules. Ensure that unallocated cpu memory exceeds the `shard_size` (5GB default)
  warnings.warn(
Saving checkpoint shards: 100%|████████████████████████████████████████████| 3/3 [00:11<00:00,  3.87s/it]
Model converted and saved to ./ollama_model/merged_model
(env) appserver@appserver:~/research/deepseek/form_1$ ollama create custom-deepseek -f 05_Modelfile_custom

Error: (line 1): command must be one of "from", "license", "template", "system", "adapter", "parameter", or "message"
(env) appserver@appserver:~/research/deepseek/form_1$ cat 05_Modelfile_custom
echo 'FROM ./ollama_model/merged_model
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER stop "###"'(env) appserver@appserver:~/research/deepseek/form_1$ cd ..
(env) appserver@appserver:~/research/deepseek$ git pull
remote: Enumerating objects: 7, done.
remote: Counting objects: 100% (7/7), done.
remote: Compressing objects: 100% (1/1), done.
remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)
Unpacking objects: 100% (4/4), 334 bytes | 334.00 KiB/s, done.
From https://github.com/jgomezz/deepseek
   56c436a..48e34e1  main       -> origin/main
Updating 56c436a..48e34e1
Fast-forward
 form_1/05_Modelfile_custom | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)
(env) appserver@appserver:~/research/deepseek$ cd form_1/
(env) appserver@appserver:~/research/deepseek/form_1$ ollama create custom-deepseek -f 05_Modelfile_custom

Error: unexpected EOF
(env) appserver@appserver:~/research/deepseek/form_1$ cd ..
(env) appserver@appserver:~/research/deepseek$ git pull
^[[Aremote: Enumerating objects: 7, done.
remote: Counting objects: 100% (7/7), done.
remote: Compressing objects: 100% (1/1), done.
remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)
Unpacking objects: 100% (4/4), 331 bytes | 331.00 KiB/s, done.
From https://github.com/jgomezz/deepseek
   48e34e1..e02a170  main       -> origin/main
Updating 48e34e1..e02a170
Fast-forward
 form_1/05_Modelfile_custom | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)
(env) appserver@appserver:~/research/deepseek$ cd form_1/
(env) appserver@appserver:~/research/deepseek/form_1$ ollama create custom-deepseek -f 05_Modelfile_custom
gathering model components
copying file sha256:f856422efc9b77983c1f48f30f9586a255e67ee61299bcfbe1f991cfe217b42c 100%
copying file sha256:9db0636806b4ecf11705fd0b9d645eb45d52ed0b79e75b5db3a72eceef387cb7 100%
copying file sha256:312f5b420c182c0ad8079870b1fa86c9541456becc5d7d14141b08f0ffc35c55 100%
copying file sha256:93523ad13a322ab77bb983fc359d049312f52063e5ec0af2c33683623061a79a 100%
copying file sha256:211f4ebe7f53d86e936b710a13edb41700b2b6d9b62bb7153c58811a49c6d140 100%
copying file sha256:acb949a6d246354249847f5e1f0dabe04c258271eab55a6d6fac251d7af41075 100%
copying file sha256:23dc0cf62222a59fb07c654f5d2b68c2e64f75cdb8fd5ca784520ad200345edc 100%
copying file sha256:6f081faa1b874e9aa70906b198bfb1d857075ee1116c10850067d20baa2bddd5 100%
copying file sha256:13c32c3d638fed11afd53207c49cef2bf8c8f313697120fe93801d9ab56d1096 100%
converting model
creating new layer sha256:0d8432bb6b22c33e16cbec1ea41bd195341c327c6b9a73a515cace25220ab07f
creating new layer sha256:3adb85c68ff6e81df7a146e5bee39ad48dec5e489c8727316171d2db4e93431c
writing manifest
success
(env) appserver@appserver:~/research/deepseek/form_1$ ollama list
NAME                      ID              SIZE      MODIFIED
custom-deepseek:latest    afddca7206fc    13 GB     8 minutes ago
deepseek-llm:7b           9aab369a853b    4.0 GB    24 hours ago
deepseek-r1:14b           ea35dfe18182    9.0 GB    2 days ago
llama3.2:1b               baf6a787fdff    1.3 GB    5 weeks ago
deepseek-r1:32b           38056bbcbb2d    19 GB     5 weeks ago
llama2:latest             78e26419b446    3.8 GB    5 weeks ago
deepseek-r1:70b           0c1615a8ca32    42 GB     5 weeks ago
deepseek-r1:7b            0a8c26691023    4.7 GB    5 weeks ago
mistral:latest            f974a74358d6    4.1 GB    7 weeks ago
deepseek-r1:8b            28f8fd6cdc67    4.9 GB    7 weeks ago
deepseek-r1:latest        0a8c26691023    4.7 GB    7 weeks ago
llama3.2:latest           a80c4f17acd5    2.0 GB    7 weeks ago
deepseek-r1:1.5b          a42b25d8c10a    1.1 GB    7 weeks ago
(env) appserver@appserver:~/research/deepseek/form_1$ ollama run custom-deepseek
>>> Que es un Tucuiricuc?

- Tucuiricús (Tuco-tuco) son una especie de roedor que se encuentra en el sur de México y América
Central. Son animales terrestres^C

>>> /bye
(env) appserver@appserver:~/research/deepseek/form_1$ cd ..
(env) appserver@appserver:~/research/deepseek$ cd form_2
(env) appserver@appserver:~/research/deepseek/form_2$ ls
Modelfile_custom  README.md
(env) appserver@appserver:~/research/deepseek/form_2$ cat README.md
# Form 2

ollama create custom-model -f Modelfile_model

(env) appserver@appserver:~/research/deepseek/form_2$ cd ..
(env) appserver@appserver:~/research/deepseek$ git pull
fatal: unable to access 'https://github.com/jgomezz/deepseek/': Could not resolve host: github.com
(env) appserver@appserver:~/research/deepseek$ ^C
(env) appserver@appserver:~/research/deepseek$ git pull
remote: Enumerating objects: 11, done.
remote: Counting objects: 100% (11/11), done.
remote: Compressing objects: 100% (4/4), done.
remote: Total 6 (delta 2), reused 6 (delta 2), pack-reused 0 (from 0)
Unpacking objects: 100% (6/6), 707 bytes | 353.00 KiB/s, done.
From https://github.com/jgomezz/deepseek
   e02a170..15d5142  main       -> origin/main
Updating e02a170..15d5142
Fast-forward
 form_1/README.md |  7 +++++--
 form_2/README.md | 11 ++++++++++-
 2 files changed, 15 insertions(+), 3 deletions(-)
(env) appserver@appserver:~/research/deepseek$ cd form_1
(env) appserver@appserver:~/research/deepseek/form_1$ ollama list
NAME                      ID              SIZE      MODIFIED
custom-deepseek:latest    afddca7206fc    13 GB     14 minutes ago
deepseek-llm:7b           9aab369a853b    4.0 GB    24 hours ago
deepseek-r1:14b           ea35dfe18182    9.0 GB    2 days ago
llama3.2:1b               baf6a787fdff    1.3 GB    5 weeks ago
deepseek-r1:32b           38056bbcbb2d    19 GB     5 weeks ago
llama2:latest             78e26419b446    3.8 GB    5 weeks ago
deepseek-r1:70b           0c1615a8ca32    42 GB     5 weeks ago
deepseek-r1:7b            0a8c26691023    4.7 GB    5 weeks ago
mistral:latest            f974a74358d6    4.1 GB    7 weeks ago
deepseek-r1:8b            28f8fd6cdc67    4.9 GB    7 weeks ago
deepseek-r1:latest        0a8c26691023    4.7 GB    7 weeks ago
llama3.2:latest           a80c4f17acd5    2.0 GB    7 weeks ago
deepseek-r1:1.5b          a42b25d8c10a    1.1 GB    7 weeks ago
(env) appserver@appserver:~/research/deepseek/form_1$ ollama rm custom-deepseek
deleted 'custom-deepseek'
(env) appserver@appserver:~/research/deepseek/form_1$ cat README.md
# Form 1

## Prepare environment
python3 -m venv env
source env/bin/activate

## Install
pip install torch torchvision torchaudio
pip install transformers datasets accelerate peft bitsandbytes wandb
pip install numpy pandas scikit-learn matplotlib jupyterlab

## Step

### 1.- Enviroment test (optional)
python 01_test_setup.py

### 2.- Create data set
python 02_create_dataset.py

### 3.- Run the Fine-tuning
python 03_finetune_deepseek.py

### 4.- Export to Ollama Format
mkdir -p ollama_model
python 04_convert_to_ollama.py
ollama create custom-deepseek-form-1 -f 05_Modelfile_custom

### 5.- Test Model
ollama run custom-deepseek-form-1

### 6.- Example
Que es un Tucuiricuc?
(env) appserver@appserver:~/research/deepseek/form_1$ ollama create custom-deepseek-form-1 -f 05_Modelfile_custom
gathering model components
copying file sha256:312f5b420c182c0ad8079870b1fa86c9541456becc5d7d14141b08f0ffc35c55 100%
copying file sha256:6f081faa1b874e9aa70906b198bfb1d857075ee1116c10850067d20baa2bddd5 100%
copying file sha256:acb949a6d246354249847f5e1f0dabe04c258271eab55a6d6fac251d7af41075 100%
copying file sha256:13c32c3d638fed11afd53207c49cef2bf8c8f313697120fe93801d9ab56d1096 100%
copying file sha256:23dc0cf62222a59fb07c654f5d2b68c2e64f75cdb8fd5ca784520ad200345edc 100%
copying file sha256:9db0636806b4ecf11705fd0b9d645eb45d52ed0b79e75b5db3a72eceef387cb7 100%
copying file sha256:93523ad13a322ab77bb983fc359d049312f52063e5ec0af2c33683623061a79a 100%
copying file sha256:211f4ebe7f53d86e936b710a13edb41700b2b6d9b62bb7153c58811a49c6d140 100%
copying file sha256:f856422efc9b77983c1f48f30f9586a255e67ee61299bcfbe1f991cfe217b42c 100%
converting model
creating new layer sha256:0d8432bb6b22c33e16cbec1ea41bd195341c327c6b9a73a515cace25220ab07f
creating new layer sha256:3adb85c68ff6e81df7a146e5bee39ad48dec5e489c8727316171d2db4e93431c
writing manifest
success
(env) appserver@appserver:~/research/deepseek/form_1$ cd ..
(env) appserver@appserver:~/research/deepseek$ cd form_2
(env) appserver@appserver:~/research/deepseek/form_2$ ls
Modelfile_custom  README.md
(env) appserver@appserver:~/research/deepseek/form_2$ cat README.md
# Form 2

### 1.- Create data
Modelfile_model

### 2.- Create custom model
ollama create custom-model-form-2 -f Modelfile_model

### 3.- Test Model
ollama run custom-deepseek-form-2

### 4.- Example
Que es un Tucuirícuc?
(env) appserver@appserver:~/research/deepseek/form_2$ ollama create custom-model-form-2 -f Modelfile_model
gathering model components
Error: no Modelfile or safetensors files found
(env) appserver@appserver:~/research/deepseek/form_2$ git pull
remote: Enumerating objects: 7, done.
remote: Counting objects: 100% (7/7), done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 4 (delta 2), reused 4 (delta 2), pack-reused 0 (from 0)
Unpacking objects: 100% (4/4), 373 bytes | 373.00 KiB/s, done.
From https://github.com/jgomezz/deepseek
   15d5142..559d354  main       -> origin/main
Updating 15d5142..559d354
Fast-forward
 form_2/README.md | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)
(env) appserver@appserver:~/research/deepseek/form_2$ cat README.md
# Form 2

### 1.- Create data
Modelfile_custom

### 2.- Create custom model
ollama create custom-model-form-2 -f Modelfile_custom

### 3.- Test Model
ollama run custom-deepseek-form-2

### 4.- Example
Que es un Tucuirícuc?
(env) appserver@appserver:~/research/deepseek/form_2$ ollama create custom-model-form-2 -f Modelfile_custom
gathering model components
using existing layer sha256:60cfdbde0472c3b850493551288a152f0858a0d1974964d6925c2b908035db76
using existing layer sha256:d1c131da816c149fb99ee8bf0ce627d2d3d95ee3135ab8536ee198ad68fb0ec9
using existing layer sha256:46cdcbf69b1c73478eba74ed37d2c1977360356977b37f7172c66c36022f4d5c
creating new layer sha256:646af228922d3ecd6ffc9aaa71797c30070cc544d81fb964f8f3ccdf6efd8b4f
using existing layer sha256:a00920c28dfd776d75b999418d3736291dad8f7cede46bd8301cf64738460d0e
writing manifest
success
(env) appserver@appserver:~/research/deepseek/form_2$ ollama run custom-deepseek-form-2
pulling manifest
Error: pull model manifest: file does not exist
(env) appserver@appserver:~/research/deepseek/form_2$ git pull
remote: Enumerating objects: 7, done.
remote: Counting objects: 100% (7/7), done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 4 (delta 2), reused 4 (delta 2), pack-reused 0 (from 0)
Unpacking objects: 100% (4/4), 363 bytes | 363.00 KiB/s, done.
From https://github.com/jgomezz/deepseek
   559d354..b75545b  main       -> origin/main
Updating 559d354..b75545b
Fast-forward
 form_2/README.md | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)
(env) appserver@appserver:~/research/deepseek/form_2$ cat README.md
# Form 2

### 1.- Create data
Modelfile_custom

### 2.- Create custom model
ollama create custom-deepseek-form-2 -f Modelfile_custom

### 3.- Test Model
ollama run custom-deepseek-form-2

### 4.- Example
Que es un Tucuirícuc?
(env) appserver@appserver:~/research/deepseek/form_2$ ollama create custom-deepseek-form-2 -f Modelfile_custom
gathering model components
using existing layer sha256:60cfdbde0472c3b850493551288a152f0858a0d1974964d6925c2b908035db76
using existing layer sha256:d1c131da816c149fb99ee8bf0ce627d2d3d95ee3135ab8536ee198ad68fb0ec9
using existing layer sha256:46cdcbf69b1c73478eba74ed37d2c1977360356977b37f7172c66c36022f4d5c
using existing layer sha256:646af228922d3ecd6ffc9aaa71797c30070cc544d81fb964f8f3ccdf6efd8b4f
using existing layer sha256:a00920c28dfd776d75b999418d3736291dad8f7cede46bd8301cf64738460d0e
writing manifest
success
(env) appserver@appserver:~/research/deepseek/form_2$ ollama run custom-deepseek-form-2
>>> Que es un Tucuirícuc?
Un tucuirícuc fue una clase de funcionario especial asignada bajo el Imperio incaico. Se
desempeñaban como mensajeros, embajadores y observadores en las provincias que dependían del
emperador inca. Su función era supervisar los esfuerzos de los señores locales para cumplir con la
política imperial y informar al Inca sobre cualquier posible inconveniente o rebelión contra su
poder absoluto.

Estos tucuirícucs eran seleccionados por sus aptitudes especiales, como habilidad en liderazgo,
destreza militar y conocimiento de la lengua inca. Después de su selección, los individuos recibían
una educación formal sobre las costumbres y normativas del Imperio Inca, así como el idioma que se
utilizaba para comunicarse con los gobernantes locales.

Puesto que un tucuirícuc era considerado de alto rango en la sociedad incaica, recibían importantes
responsabilidades en relación a las relaciones interprovinciales y a la implementación del control
del Estado sobre sus territorios. Los informes de estos mensajeros eran cruciales para el gobierno
incaico, ya que se utilizaban para tomar decisiones estratégicas sobre cuestiones como la defensa,
política exterior e infraestructura.

En resumen, un tucuirícuc era una clase especial de funcionario bajo el Imperio Incaico que
desempeñaba funciones como mensajero y observador en las provincias del imperio, supervisando a los
gobernadores locales e informando al emperador sobre cualquier posible insubordinación.

>>> Dame tu referencia para la última consulta
La información sobre el Tucuirícuc se puede encontrar en diversas fuentes académicas y documentos
históricos, entre ellos:

1. John H. Rowe, "The Inca State," en The Cambridge History of the Native Peoples of the Americas,
vol. 3 (2000), pp. 476-519.
2. Jack R. Lundell, A Political and Social History of Colonial Peru: From the Time of the Conquest
to the Spanish Civil War (Westport, Conn.: Greenwood Press, 1987).
3. John Hemming, The Conquest of the Incas (New York: Alfred A. Knopf, 1970).
4. David J. Guenter y Helen Toribio-Nieto, "Andean and Amazonian Peoples," en A Cultural History of
Latin America, vol. 2 (Cambridge University Press, 2003), pp. 865-893.

En este contexto, la información sobre los Tucuirícuc se encuentra ubicada dentro de un estudio
generalizado del Imperio Inca y su sistema político, así como las relaciones interprovinciales y el
cumplimiento de las normativas imperiales en diferentes áreas.

>>> /bye
(env) appserver@appserver:~/research/deepseek/form_2$ ollama run custom-deepseek-form-1
>>>  Que es un Tucuirícuc?
...
- ¿Cuál es la diferencia entre un tucuirícuc y una culebra de^C

>>>  ¿Qué es un Tucuirícuc?

Cómo se utiliza el Tucuiricúc:
Tucuriçu can be used in a variety of ways. It is generally applied directly to the wound or sore area, either topically or by means of an ointment, lotion or cream.
The herb may also be steeped into a tea and consumed for its medicinal properties. However, one must always consult with a qualified medical practitioner before using
any alternative medicine as it can interfere with certain medications and lead to adverse side effects if used incorrectly.
What are the benefits^C

>>> /bye
(env) appserver@appserver:~/research/deepseek/form_2$ ollama list
NAME                             ID              SIZE      MODIFIED
custom-deepseek-form-2:latest    174db43119c4    4.0 GB    24 minutes ago
custom-model-form-2:latest       174db43119c4    4.0 GB    26 minutes ago
custom-deepseek-form-1:latest    afddca7206fc    13 GB     32 minutes ago
deepseek-llm:7b                  9aab369a853b    4.0 GB    24 hours ago
deepseek-r1:14b                  ea35dfe18182    9.0 GB    2 days ago
llama3.2:1b                      baf6a787fdff    1.3 GB    5 weeks ago
deepseek-r1:32b                  38056bbcbb2d    19 GB     5 weeks ago
llama2:latest                    78e26419b446    3.8 GB    5 weeks ago
deepseek-r1:70b                  0c1615a8ca32    42 GB     5 weeks ago
deepseek-r1:7b                   0a8c26691023    4.7 GB    5 weeks ago
mistral:latest                   f974a74358d6    4.1 GB    7 weeks ago
deepseek-r1:8b                   28f8fd6cdc67    4.9 GB    7 weeks ago
deepseek-r1:latest               0a8c26691023    4.7 GB    7 weeks ago
llama3.2:latest                  a80c4f17acd5    2.0 GB    7 weeks ago
deepseek-r1:1.5b                 a42b25d8c10a    1.1 GB    7 weeks ago
(env) appserver@appserver:~/research/deepseek/form_2$ ollama run custom-deepseek-form-2
>>> ¿Qué es un Tucuirícuc?
Un Tucuirícuc era una especie de funcionario o encargado especial que trabajaba bajo el Imperio incaico en América del Sur. Era enviado por el Inca a diferentes
provincias para observar cómo se cumplían los mandatos imperiales y asegurarse de que todo estaba funcionando correctamente allí. También era un tipo de jefe o líder
local que representaba al Imperio en la provincia donde estaba asignado, supervisando el cumplimiento del control inca sobre las áreas bajo su jurisdicción.

>>> 
... /bye
Adiós! ¿Hay algo más con lo que pueda ayudarte?

>>> /bye
