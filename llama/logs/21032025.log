/Llama-2-7b-hf is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-2-7b-hf to ask for access.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/appserver/research/deepseek/llama/form_1/03_finetune_llama.py", line 150, in <module>
    main()
  File "/home/appserver/research/deepseek/llama/form_1/03_finetune_llama.py", line 76, in main
    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/appserver/research/deepseek/llama/form_1/env/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py", line 930, in from_pretrained
    config = AutoConfig.from_pretrained(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/appserver/research/deepseek/llama/form_1/env/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py", line 1096, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/appserver/research/deepseek/llama/form_1/env/lib/python3.12/site-packages/transformers/configuration_utils.py", line 594, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/appserver/research/deepseek/llama/form_1/env/lib/python3.12/site-packages/transformers/configuration_utils.py", line 653, in _get_config_dict
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/home/appserver/research/deepseek/llama/form_1/env/lib/python3.12/site-packages/transformers/utils/hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/appserver/research/deepseek/llama/form_1/env/lib/python3.12/site-packages/transformers/utils/hub.py", line 481, in cached_files
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Llama-2-7b-hf.
403 Client Error. (Request ID: Root=1-67ddcb95-095e073c7cbfb97c1d5abef2;d04423ea-cfbd-4a16-9fb1-7324930a0a5a)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/config.json.
Access to model meta-llama/Llama-2-7b-hf is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-2-7b-hf to ask for access.
